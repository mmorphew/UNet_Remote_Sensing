{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have not yet run the preprocessing notebook (Tiff_To_NumPy.ipynb), please do that first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import concatenate, add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't use all of these loss metrics at first, but let's go ahead and define them in case we decide to change our loss function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "    \"\"\"\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    \n",
    "    The jaccard distance loss is usefull for unbalanced datasets. This has been\n",
    "    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n",
    "    gradient.\n",
    "    \n",
    "    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "    \n",
    "    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n",
    "    @author: wassname\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the files we preprocessed in the last notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(r'.\\data.npy')\n",
    "labels = np.load(r'.\\label.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell Tensorflow the size of our input image. This will depend on how we resized the images during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 512\n",
    "ny = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[:,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized difference vegetation index is a common measurement used in remote sensing. Let's add it as a fifth channel to see if it improves results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = np.expand_dims((data[:,:,:,0]-data[:,:,:,1])/(data[:,:,:,0]+data[:,:,:,1]), axis=-1)\n",
    "data = np.append(data, ndvi, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve learning, let's normalize by subtracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization across all samples (band specific)\n",
    "data_scaled = np.zeros(np.shape(data))\n",
    "data_normalized = np.zeros((np.shape(data)))\n",
    "for i in range(np.shape(data)[-1]):\n",
    "    data_mean = np.mean(data[:,:,:,i])\n",
    "    data_std = np.std(data[:,:,:,i])\n",
    "    data_scaled[:,:,:,i] = (data[:,:,:,i]-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_scaled\n",
    "y = labels[:,:,:,:-1] # exclude clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data and labels as we want them, we can split our dataset into a portion for training and a portion for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.20, shuffle=True, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further augment our training data by introducing data augmentations where we flip the images in various ways, add noise, etc. For right now, I'll leave this commented out, just to establish a baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation on just the training data\n",
    "## Image Augmentation\n",
    "# Vertical Image\n",
    "#Vx = [np.flip(x, axis=1) for x in x_train]\n",
    "#Vy = [np.flip(x, axis=1) for x in y_train]\n",
    "\n",
    "# Horizontal Image\n",
    "#Hx = [np.flip(x, axis=2) for x in x_train]\n",
    "#Hy = [np.flip(x, axis=2) for x in y_train]\n",
    "\n",
    "# Horizontal Vertical Image\n",
    "#HVx = [np.flip(x, axis=2) for x in Vx]\n",
    "#HVy = [np.flip(x, axis=2) for x in Vy]\n",
    "\n",
    "# Appending the augmented image and mask to the main dataset.\n",
    "#x_train = np.append(x_train, Vx, axis=0)\n",
    "#y_train = np.append(y_train, Vy, axis=0)\n",
    "\n",
    "#x_train = np.append(x_train, Hx, axis=0)\n",
    "#y_train = np.append(y_train, Hy, axis=0)\n",
    "\n",
    "#x_train = np.append(x_train, HVx, axis=0)\n",
    "#y_train = np.append(y_train, HVy, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the neural network. The basic building block is a convolutional block with two 2D convolutional operators, along with the potential for batch normalization, and finally an activation function. I have it defined as ReLU for right now, but this can be easily altered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, l2_lambda=0, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\", kernel_regularizer=regularizers.l2(l2_lambda))(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\", kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=32, dropout=0.5, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(5, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to start training. Let's create a model object, compile it, and summarize it so we can make sure the layers were built the way we wanted them to be built by Keras. We'll also define our optimizer, Adam, and pick a loss function and tracking metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((nx, ny, 5), name='img')\n",
    "model = get_unet(input_img, n_filters=32, dropout=0.5, batchnorm=True)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"categorical_accuracy\", f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks instruct Tensorflow how to behave during training. We can institute early stopping, reductions in training loss, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-test-4.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.fit(x_train, y_train, batch_size=1, epochs=100, callbacks=callbacks,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot our results to see how our training and predictions look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-test-4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set)\n",
    "model.evaluate(x_val, y_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "preds_train = model.predict(x_train, verbose=1)\n",
    "preds_val = model.predict(x_val, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold predictions\n",
    "\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(20, 10))\n",
    "    r_band = (X[ix,:,:,0]-np.min(X[ix,:,:,0]))/(np.max(X[ix,:,:,0])-np.min(X[ix,:,:,0]))\n",
    "    g_band = (X[ix,:,:,1]-np.min(X[ix,:,:,1]))/(np.max(X[ix,:,:,1])-np.min(X[ix,:,:,1]))\n",
    "    b_band = (X[ix,:,:,2]-np.min(X[ix,:,:,2]))/(np.max(X[ix,:,:,2])-np.min(X[ix,:,:,2]))\n",
    "    RGB = np.stack((r_band, g_band, b_band), axis=-1)\n",
    "    print(np.shape(RGB))\n",
    "    im0 = ax[0,0].imshow(RGB)\n",
    "    #if has_mask:\n",
    "        #ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    fig.colorbar(im0, ax=ax[0,0], fraction=0.046, pad=0.04)\n",
    "    ax[0,0].set_title('Remote Sensing Image')\n",
    "\n",
    "    im1 = ax[0,1].imshow(y[ix,:,:,0].squeeze())\n",
    "    ax[0,1].set_title('Impervious Surfaces')\n",
    "    fig.colorbar(im1, ax=ax[0,1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    im2 = ax[1,0].imshow(preds[ix,:,:,0].squeeze(), vmin=0, vmax=1)\n",
    "    #if has_mask:\n",
    "        #ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    fig.colorbar(im2, ax=ax[1,0], fraction=0.046, pad=0.04)\n",
    "    ax[1,0].set_title('Impervious Surfaces Predicted')\n",
    "    \n",
    "    im3 = ax[1,1].imshow(binary_preds[ix,:,:,0].squeeze(), vmin=0, vmax=1)\n",
    "    #if has_mask:\n",
    "        #ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    fig.colorbar(im3, ax=ax[1,1], fraction=0.046, pad=0.04)\n",
    "    ax[1,1].set_title('Impervious Surfaces Predicted (Binary)')\n",
    "    fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_all(X, y, preds, binary_preds, ix=None, filename='Sample.png'):\n",
    "    import matplotlib\n",
    "\n",
    "    matplotlib.rc('xtick', labelsize=20) \n",
    "    matplotlib.rc('ytick', labelsize=20) \n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(20, 50))\n",
    "    r_band = (X[ix,:,:,0]-np.min(X[ix,:,:,0]))/(np.max(X[ix,:,:,0])-np.min(X[ix,:,:,0]))\n",
    "    g_band = (X[ix,:,:,1]-np.min(X[ix,:,:,1]))/(np.max(X[ix,:,:,1])-np.min(X[ix,:,:,1]))\n",
    "    b_band = (X[ix,:,:,2]-np.min(X[ix,:,:,2]))/(np.max(X[ix,:,:,2])-np.min(X[ix,:,:,2]))\n",
    "    RGB = np.stack((r_band, g_band, b_band), axis=-1)\n",
    "\n",
    "    im0 = ax[0,0].imshow(RGB)\n",
    "    #if has_mask:\n",
    "        #ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "\n",
    "    ax[0,0].set_title('Remote Sensing Image', fontsize=30)\n",
    "    \n",
    "        \n",
    "    im1 = ax[0,1].imshow(X[ix,:,:,4].squeeze(), cmap='gray')\n",
    "\n",
    "    ax[0,1].set_title('NDVI', fontsize=30)\n",
    "    \n",
    "    im2 = ax[1,0].imshow(X[ix,:,:,3].squeeze(), cmap='gray')\n",
    "\n",
    "    ax[1,0].set_title('Filtered DSM', fontsize=30)\n",
    "    \n",
    "    total_mask = np.zeros((256, 256, 3))\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            # impervious surface\n",
    "            if(y[ix,i,j,0]==1):\n",
    "                total_mask[i,j,0]=1\n",
    "                total_mask[i,j,1]=1\n",
    "                total_mask[i,j,2]=1\n",
    "            # building\n",
    "            elif(y[ix,i,j,1]==1):\n",
    "                total_mask[i,j,0]=0\n",
    "                total_mask[i,j,1]=0\n",
    "                total_mask[i,j,2]=1\n",
    "            # low vegetation\n",
    "            elif(y[ix,i,j,2]==1):\n",
    "                total_mask[i,j,0]=0\n",
    "                total_mask[i,j,1]=1\n",
    "                total_mask[i,j,2]=1\n",
    "            # tree\n",
    "            elif(y[ix,i,j,3]==1):\n",
    "                total_mask[i,j,0]=0\n",
    "                total_mask[i,j,1]=1\n",
    "                total_mask[i,j,2]=0\n",
    "            # car\n",
    "            elif(y[ix,i,j,4]==1):\n",
    "                total_mask[i,j,0]=1\n",
    "                total_mask[i,j,1]=0\n",
    "                total_mask[i,j,2]=0\n",
    "\n",
    "                \n",
    "    im3 = ax[1,1].imshow(total_mask)\n",
    "    ax[1,1].set_title('Image Mask', fontsize=30)\n",
    "    \n",
    "    im4 = ax[2,0].imshow(binary_preds[ix,:,:,0].squeeze(), vmin=0, vmax=1)\n",
    "\n",
    "    ax[2,0].set_title('Impervious Surface Predicted (Binary)', fontsize=30)\n",
    "    \n",
    "    im5 = ax[2,1].imshow(binary_preds[ix,:,:,1].squeeze(), vmin=0, vmax=1)\n",
    "\n",
    "    ax[2,1].set_title('Building Predicted (Binary)', fontsize=30)\n",
    "    \n",
    "    im6 = ax[3,0].imshow(binary_preds[ix,:,:,2].squeeze(), vmin=0, vmax=1)\n",
    "\n",
    "    ax[3,0].set_title('Low Vegetation Predicted (Binary)', fontsize=30)\n",
    "    \n",
    "    im7 = ax[3,1].imshow(binary_preds[ix,:,:,3].squeeze(), vmin=0, vmax=1)\n",
    "\n",
    "    ax[3,1].set_title('Trees Predicted (Binary)', fontsize=30)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    \n",
    "    im8 = ax[4,0].imshow(binary_preds[ix,:,:,4].squeeze(), vmin=0, vmax=1)\n",
    "\n",
    "    ax[4,0].set_title('Cars Predicted (Binary)', fontsize=30)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    \n",
    "    total_preds = np.zeros((256,256,3))\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            # impervious surface\n",
    "            if(np.max(preds[ix,i,j])==preds[ix,i,j,0]):\n",
    "                total_preds[i,j,0]=1\n",
    "                total_preds[i,j,1]=1\n",
    "                total_preds[i,j,2]=1\n",
    "            # building\n",
    "            elif(np.max(preds[ix,i,j])==preds[ix,i,j,1]):\n",
    "                total_preds[i,j,0]=0\n",
    "                total_preds[i,j,1]=0\n",
    "                total_preds[i,j,2]=1\n",
    "            # low vegetation\n",
    "            elif(np.max(preds[ix,i,j])==preds[ix,i,j,2]):\n",
    "                total_preds[i,j,0]=0\n",
    "                total_preds[i,j,1]=1\n",
    "                total_preds[i,j,2]=1\n",
    "            # tree\n",
    "            elif(np.max(preds[ix,i,j])==preds[ix,i,j,3]):\n",
    "                total_preds[i,j,0]=0\n",
    "                total_preds[i,j,1]=1\n",
    "                total_preds[i,j,2]=0\n",
    "            # car\n",
    "            elif(np.max(preds[ix,i,j])==preds[ix,i,j,4]):\n",
    "                total_preds[i,j,0]=1\n",
    "                total_preds[i,j,1]=0\n",
    "                total_preds[i,j,2]=0\n",
    "    im9 = ax[4,1].imshow(total_preds)\n",
    "\n",
    "    ax[4,1].set_title('All Maximum Class Predictions', fontsize=30)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=22)\n",
    "    fig.tight_layout();\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if validation data looks all right\n",
    "plot_sample_all(x_val, y_val, preds_val, preds_val_t, ix=2, filename='test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if valid data looks all right\n",
    "plot_sample(x_val, y_val, preds_val, preds_val_t, ix=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, just for good measure, let's calculate some receiver operator characteristics on either the total dataset, or the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = np.concatenate((x_train, x_val), axis=0)\n",
    "y_total = np.concatenate((y_train, y_val), axis=0)\n",
    "pred_total = np.concatenate((preds_train_t, preds_val_t), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_total.ravel(), pred_total.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_roc_metrics(y_real, y_predict):\n",
    "\n",
    "    c_matrix = confusion_matrix(y_real.ravel(), y_predict.ravel())\n",
    "    f1 = f1_score(y_real.ravel(), y_predict.ravel())\n",
    "    recall = recall_score(y_real.ravel(), y_predict.ravel())\n",
    "    precision = precision_score(y_real.ravel(), y_predict.ravel())\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(c_matrix)\n",
    "    print(\"F1 score: {:.4f}\".format(f1))\n",
    "    print(\"Recall score: {:.4f}\".format(recall))\n",
    "    print(\"Precision score: {:.4f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_roc_metrics(y_val, preds_val_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
